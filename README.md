EmoReflector Project

EmoReflector is a social robot designed to interact with the elderly people based on emotions. It is implemented by a robust emotion recognition module using deep-learning models (CNN and ResNet-18)
and embeding the algorithm into a micro-controller, Raspberry Pi. The robot has a camera to capture facial videos, and the module classifies the emotions of the user into negative or non-negative emotions.
Based on the recognized emotions, if the emotions are classified negative, the robot will respond using an audio output.

Instructions on how to run the code: 
Step 1: Open the drive link in the GitHub.  
Step 2: Click on the executable file. 
Step 3: Google Colab will open. 
Step 4: Run the code. 

Additional Information: No need to re-train the model. Just skip that code and load the model as it is already saved in the same path as the executable file.  
If Raspberry Pi 4B with integrated camera and speaker module is available:
Step 1: Add your email into the Raspberry Pi executable where it is written to add your email.
Step 2: Run the code

A link to the GitHub repository: 
https://github.com/Aafia1223/GP1_Group1_EmoReflector_Dr.Heyam.git 
A link to the Google Drive: 
https://drive.google.com/drive/folders/1JOOhLMOd4iXx2nrPqSp9wVXox46lwUcT?usp=sharin
 g
